{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e3028ec-59e2-4591-8fa8-956d138217d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from typing import Dict, Union, Callable\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from dataclasses import dataclass\n",
    "import scipy.stats\n",
    "import graphs\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72976cc0-e56c-4cf7-b2ea-c0cb4bd43641",
   "metadata": {},
   "source": [
    "## Having a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae4394f4-1121-4dc4-b69f-5cdf523e78f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('trainset.csv')\n",
    "#_,ax = plt.subplots(nrows=len(dataset.columns), ncols=1, figsize=(10,12))\n",
    "#plt.tight_layout()\n",
    "#for i,column in enumerate(dataset.columns):\n",
    "#    ax[i].hist(dataset[column])\n",
    "#    ax[i].set_xlabel(column)\n",
    "\n",
    "# I'll start by considering quality as a continuous variable with no further changes\n",
    "data = dataset.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211538b-20f5-4508-bad6-192fcba95d15",
   "metadata": {},
   "source": [
    "## Learning a linear gaussian bayes net with a given adjacency matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba775804-7745-4718-b002-1d27a9cf7ede",
   "metadata": {},
   "source": [
    "A linear gaussian bayes net describes a gaussian probability distribution. Each node in such a network itself represents a gaussian distribution over one attribute/variable. Edges between nodes signify dependence of one variable on the other. ($A \\rightarrow B$ means $A$ influences $B$, $B$ is dependent on $A$)\n",
    "\n",
    "For each node $x_i$ , we define its conditional probability distribution:\n",
    "$$\n",
    "p(x_i | \\text{parents}(i)) = \\mathcal{N}\\left( \\beta_{i0} + \\sum_{i \\in \\text{parents}(j)} \\beta_{ij} x_j, \\sigma_i \\right)\n",
    "$$\n",
    "with parameters:\n",
    "- $\\beta_{ij}$: coefficients describing the way $x_j$ influences $x_i$\n",
    "- $\\beta_{i0}$: offset \n",
    "- $\\sigma_i$: conditional variance of $x_i$ (conditioned on $\\text{parents}(i)$)\n",
    "\n",
    "We compute the coefficients and offset by fitting a linear regression, and compute the conditional variance using a formula derived from its definition:\n",
    "$$\n",
    "\\text{Var}[Y|X] = E \\left[(Y - E[Y|X])^2 \\right] \\\\\n",
    "\\text{sampleVar}(y|x) = \\frac{1}{m-1} \\sum_{i=1}^m (y_i - \\hat{y}_x)^2\n",
    "$$\n",
    "where:\n",
    "- $y_i$ is the value of this attribute for each datapoint\n",
    "- $\\hat{y}_x$ is the predicted value of $y_i$ given the values of the other attributes $x$\n",
    "\n",
    "##### Likelihood:\n",
    "Given some data $X = (x^{(1)}, x^{(2)}, ..., x^{(m)})$:\n",
    "$$\n",
    "L(S) = \\prod_{i=1}^m p(x^{(i)} | S, \\theta)\n",
    "$$\n",
    "where $S$ represents the model structure (in our case, the adjacency matrix), and $\\theta$ represents the learned parameters.\n",
    "We only view the likelihood as a function of $S$.\n",
    "We can write down the likelihood for our models in short:\n",
    "$$\n",
    "L(\\text{parents}) = \\prod_{j=1}^m \\prod_{i=1}^n p(x_i^{(j)} | \\text{parents}(x_i)^{(j)}) = \\prod_{j=1}^m \\prod_{i=1}^n  \\mathcal{N}\\left( \\beta_{i0} + \\sum_{i \\in \\text{parents}(k)} \\beta_{ik} x_k^{(j)}, \\sigma_i \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9244e6f0-a90a-4171-b986-dec24c3bf1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class StaticParam:\n",
    "    mu: float\n",
    "    sigma: float\n",
    "\n",
    "@dataclass\n",
    "class DependentParam:\n",
    "    coefficients: np.ndarray\n",
    "    offset: float\n",
    "    sigma: float\n",
    "\n",
    "Param = Union[StaticParam, DependentParam] # A param is either static or dependent\n",
    "\n",
    "class GaussNet():\n",
    "    def __init__(self, adj: np.ndarray):\n",
    "        self.adj = adj\n",
    "        self.n = adj.shape[0]  # number of variables\n",
    "        self.params: Dict[int, Param] = {}  # parameters defining gaussian distribution for each variable\n",
    "    \n",
    "    # mode=0 uses explicit linear regressions from sklearn while\n",
    "    # mode=1 uses computations using the covariance matrix with no further packages used\n",
    "    def fit(self, data: np.ndarray, mode=1):\n",
    "        if mode == 1:\n",
    "            return self.__fit1(data)\n",
    "        else:\n",
    "            return self.__fit2(data)\n",
    "    \n",
    "    def __fit1(self, data: np.ndarray):\n",
    "        def compute_static_params():\n",
    "            target_data = data[:, node_idx]\n",
    "            mu = np.mean(target_data)\n",
    "            sigma = np.var(target_data)\n",
    "            return StaticParam(mu, sigma)\n",
    "            \n",
    "        def compute_dependent_params():\n",
    "            target_data = data[:, node_idx]\n",
    "            predictor_data = data[:, graphs.parents(self.adj, node_idx)]\n",
    "            reg = LinearRegression().fit(predictor_data, target_data) # fit a linear regression\n",
    "            coefficients = reg.coef_\n",
    "            offset = reg.intercept_\n",
    "            predicted_data = reg.predict(predictor_data)\n",
    "            sigma = (1/(m-1)) * np.sum((target_data - predicted_data)**2)\n",
    "            return DependentParam(coefficients, offset, sigma)\n",
    "        \n",
    "        m = data.shape[0]\n",
    "        for node_idx in range(self.n):\n",
    "            if graphs.parents(self.adj, node_idx) == []:  # No parents\n",
    "                self.params[node_idx] = compute_static_params()\n",
    "            else:\n",
    "                self.params[node_idx] = compute_dependent_params()\n",
    "        return self\n",
    "    \n",
    "    def __fit2(self, data: np.ndarray):\n",
    "        def compute_static_params() -> StaticParam:\n",
    "            target_data = data[:, node_idx]\n",
    "            mu = np.mean(target_data)\n",
    "            sigma = np.var(target_data)\n",
    "            return StaticParam(mu, sigma)\n",
    "        def compute_dependent_params() -> DependentParam:\n",
    "            target_data = data[:, node_idx]\n",
    "            parents = graphs.parents(self.adj, node_idx)\n",
    "            mu_I = np.mean(target_data)\n",
    "            sigma_full = np.cov(data, rowvar=False)\n",
    "            sigma_IJ = self.__myindex(sigma_full, node_idx, parents)\n",
    "            sigma_JJ = self.__myindex(sigma_full, parents, parents)\n",
    "            mu_J = np.mean(data[:,parents], axis=0)\n",
    "            sigma_II = self.__myindex(sigma_full, node_idx, node_idx)\n",
    "            sigma_JI = self.__myindex(sigma_full, parents, node_idx)\n",
    "            \n",
    "            offset = np.squeeze(mu_I - sigma_IJ @ np.linalg.inv(sigma_JJ) @ np.atleast_2d(mu_J).T)\n",
    "            coefficients = sigma_IJ @ np.linalg.inv(sigma_JJ)\n",
    "            sigma = np.squeeze(sigma_II - coefficients @ sigma_JI)\n",
    "            return DependentParam(coefficients.reshape(len(parents)), offset.item(), sigma.item())\n",
    "        for node_idx in range(self.n):\n",
    "            if graphs.parents(self.adj, node_idx) == []:  # No parents\n",
    "                self.params[node_idx] = compute_static_params()\n",
    "            else:\n",
    "                self.params[node_idx] = compute_dependent_params()\n",
    "        return self\n",
    "\n",
    "    def predict(self, data: np.ndarray, node_idx: int, toround=False):\n",
    "        predictors = data[:, graphs.parents(self.adj, node_idx)]\n",
    "        param = self.params[node_idx]\n",
    "        if type(param) == StaticParam:\n",
    "            if toround:\n",
    "                return np.repeat(np.around(param.mu), data.shape[0])\n",
    "            else:\n",
    "                return np.repeat(param.mu, data.shape[0])\n",
    "        else:\n",
    "            if toround:\n",
    "                return np.around(param.offset + predictors @ param.coefficients)\n",
    "            else:\n",
    "                return param.offset + predictors @ param.coefficients\n",
    "\n",
    "    def accuracy(self, data: np.ndarray, node_idx: int): # Assumes that node_idx is a categorical variable obtained by rounding the estimate\n",
    "        predicted = np.reshape(self.predict(data, node_idx, toround=True), data.shape[0])\n",
    "        return np.count_nonzero(predicted == data[:,node_idx]) / data.shape[0]\n",
    "\n",
    "    def loglikelihood(self, data: np.ndarray):\n",
    "        acc = 0\n",
    "        for node_idx in range(self.n):\n",
    "            mus = np.squeeze(self.predict(data, node_idx))\n",
    "            acc += np.sum(scipy.stats.norm.logpdf(data[:,node_idx], mus, self.params[node_idx].sigma))\n",
    "        return acc\n",
    "    \n",
    "    def num_params(self):\n",
    "        acc = 0\n",
    "        for _,param in self.params.items():\n",
    "            if type(param) == StaticParam:\n",
    "                acc += 2\n",
    "            else:\n",
    "                acc += 2 + param.coefficients.shape[0]\n",
    "        return acc\n",
    "    \n",
    "    def __myindex(self, arr, idx_I, idx_J=[]): # Leaves only the indices idx_I and idx_J in array arr\n",
    "        if arr.ndim > 2: return arr\n",
    "        if arr.ndim == 1: return arr[idx_I]\n",
    "        if arr.ndim == 2: return np.atleast_2d(arr[idx_I,:])[:,idx_J]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f514d16-dedf-4a18-9786-d5cea55b4621",
   "metadata": {},
   "source": [
    "#### We'll try gauss nets with both modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c0fe34b-5024-4c51-847a-8d608b0cb24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DependentParam(coefficients=array([0.35419866]), offset=1.9564383703769535, sigma=0.5232316131752069)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attributes = data.shape[1]\n",
    "test_adj = np.zeros((num_attributes, num_attributes))\n",
    "test_adj[10,11] = 1 # let's say that residual sugar predicts quality\n",
    "net1 = GaussNet(test_adj)\n",
    "net1.fit(data)\n",
    "net1.params[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd20f225-3d8f-4bbc-8a22-c9e3a4e23f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DependentParam(coefficients=array([0.35419866]), offset=1.9564383703769535, sigma=0.5232316131752068)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attributes = data.shape[1]\n",
    "test_adj = np.zeros((num_attributes, num_attributes))\n",
    "test_adj[10,11] = 1 # let's say that residual sugar predicts quality\n",
    "net2 = GaussNet(test_adj)\n",
    "net2.fit(data, mode=2) # Using the other mode this time\n",
    "net2.params[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74337809-cdcb-49f5-9ad0-911b0d918acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5504587155963303\n",
      "0.5504587155963303\n",
      "-169945633.35283077\n",
      "-169945633.35283077\n"
     ]
    }
   ],
   "source": [
    "print(net1.accuracy(data, 11))\n",
    "print(net2.accuracy(data, 11))\n",
    "print(net1.loglikelihood(data))\n",
    "print(net2.loglikelihood(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b932a-aa97-4e46-b6aa-5687b38a24cc",
   "metadata": {},
   "source": [
    "#### Both modes seem are equivalent!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f549340-703f-44eb-8e81-47a65325561d",
   "metadata": {},
   "source": [
    "### For accuracy, only the last column matters, so let's just try all possibilities\n",
    "\n",
    "That's gonna be $2^{11}=2048$ possibilites.\n",
    "We'll save the maximum accuracy achieved for each number of attributes used in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e21658f-4e07-48e2-83d5-63e7743e03f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy for 0 attributes used: 0.390325271059216, achieved using:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Maximum accuracy for 1 attributes used: 0.5504587155963303, achieved using:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Maximum accuracy for 2 attributes used: 0.5646371976647206, achieved using:\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "Maximum accuracy for 3 attributes used: 0.5746455379482902, achieved using:\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "Maximum accuracy for 4 attributes used: 0.5738115095913261, achieved using:\n",
      "[0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "Maximum accuracy for 5 attributes used: 0.5863219349457881, achieved using:\n",
      "[0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "Maximum accuracy for 6 attributes used: 0.5863219349457881, achieved using:\n",
      "[0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      "Maximum accuracy for 7 attributes used: 0.5888240200166805, achieved using:\n",
      "[0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      "Maximum accuracy for 8 attributes used: 0.5879899916597164, achieved using:\n",
      "[1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0.]\n",
      "Maximum accuracy for 9 attributes used: 0.5921601334445371, achieved using:\n",
      "[1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0.]\n",
      "Maximum accuracy for 10 attributes used: 0.5863219349457881, achieved using:\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.]\n",
      "Maximum accuracy for 11 attributes used: 0.5838198498748958, achieved using:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "columns = np.array(list(itertools.product([0,1], repeat=11)))\n",
    "columns = np.hstack((columns, np.atleast_2d(np.zeros(2**11)).T)) # add a 0, so we dont predict quality by quality\n",
    "\n",
    "max_acc = {}\n",
    "max_acc_idx = {}\n",
    "for i in range(12):\n",
    "    max_acc[i] = -1\n",
    "    max_acc_idx[i] = -1\n",
    "\n",
    "for idx,column in enumerate(columns):\n",
    "    adj = np.zeros((data.shape[1], data.shape[1]))\n",
    "    adj[:,11] = column\n",
    "    acc = GaussNet(adj).fit(data).accuracy(data, 11)\n",
    "    num_attr = np.count_nonzero(column)\n",
    "    if acc > max_acc[num_attr]:\n",
    "        max_acc[num_attr] = acc\n",
    "        max_acc_idx[num_attr] = idx\n",
    "\n",
    "for i in range(12):\n",
    "    column = columns[max_acc_idx[i]]\n",
    "    print(f'Maximum accuracy for {i} attributes used: {max_acc[i]}, achieved using:')\n",
    "    print(column)\n",
    "    adj = np.zeros((data.shape[1], data.shape[1]))\n",
    "    adj[:,11] = column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f986d7-aee6-4d11-9093-b2825c227cd8",
   "metadata": {},
   "source": [
    "# Structure Learning\n",
    "## Score-Based Algorithms\n",
    "For the next algorithms, we will be adding edges to, and removing them from, the graph.\n",
    "When adding edges, we need to make sure we're keeping the DAG structure.\n",
    "An added edge can cause a cycle to appear.\n",
    "In this case, the new edge $A \\rightarrow B$ will be part of the cycle.\n",
    "A cycle will appear if and only if there was a path from $B$ to $A$ in the DAG before the edge was added.\n",
    "We can check for such a path with a search (in this case, DFS) starting from $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6a89d6a-d2d3-4bb1-9611-512f1b7d5ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: False\n",
      "2: True\n",
      "3: True\n",
      "4: False\n",
      "4: True\n",
      "5: False\n",
      "6: False\n",
      "7: True\n",
      "8: False\n",
      "9: False\n"
     ]
    }
   ],
   "source": [
    "# Some test cases for finding paths in a graph\n",
    "test_adj = np.zeros((5,5))\n",
    "print(f'1: {graphs.path_exists(test_adj, 0, 1)}')\n",
    "print(f'2: {graphs.path_exists(test_adj, 0, 0)}')\n",
    "test_adj[0,3] = 1\n",
    "print(f'3: {graphs.path_exists(test_adj, 0, 3)}')\n",
    "print(f'4: {graphs.path_exists(test_adj, 3, 0)}')\n",
    "test_adj[3,4] = 1\n",
    "print(f'4: {graphs.path_exists(test_adj, 0, 4)}')\n",
    "print(f'5: {graphs.path_exists(test_adj, 4, 3)}')\n",
    "print(f'6: {graphs.path_exists(test_adj, 4, 0)}')\n",
    "test_adj[3,2] = 1\n",
    "test_adj[3,1] = 1\n",
    "test_adj[4,4] = 1\n",
    "test_adj[4,1] = 1\n",
    "test_adj[4,2] = 1\n",
    "print(f'7: {graphs.path_exists(test_adj, 0, 4)}')\n",
    "print(f'8: {graphs.path_exists(test_adj, 4, 3)}')\n",
    "print(f'9: {graphs.path_exists(test_adj, 4, 0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e827ad7-cf00-4aca-849c-d0d64140c261",
   "metadata": {},
   "source": [
    "## Scores\n",
    "### Bayesian Information Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e33b4f82-1059-4227-ae87-479b3aba7215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BIC(loglikelihood: float, num_params: int, num_datapoints: int) -> float:\n",
    "    return num_params*np.log(num_datapoints) - 2*loglikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15b6a66-5798-4670-aa6a-ae1811846e62",
   "metadata": {},
   "source": [
    "### Akaike Information Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1d20c1c-bcb4-4d9e-942a-a663769b3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AIC(loglikelihood: float, num_params: int, num_datapoints: int) -> float:\n",
    "    return 2*num_params - 2*loglikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051683fa-41ef-4c62-aa73-cff0f440dcf3",
   "metadata": {},
   "source": [
    "## Search Algorithms\n",
    "### Local Additive Search\n",
    "We start with an empty graph (no edges) and gradually add the legal edge that brings the highest score-increase, until there is none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84ec1d6c-f849-433c-8699-d3377bde5985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_additive_search(n: int, data: np.ndarray, metric: Callable) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Performs a local additive search to find an adjacency matrix for a\n",
    "    linear gaussian network that fits the data well.\n",
    "    It uses 'metric' as a score to evaluate gaussian networks.\n",
    "    'metric' should take 3 parameters: \n",
    "        the loglikelihood, the number of parameters and the number of datapoints\n",
    "    \"\"\"\n",
    "    adj = np.zeros((n,n))  # start with empty adjacency matrix\n",
    "    net = GaussNet(adj).fit(data)\n",
    "    highest_score = metric(net.loglikelihood(data), net.num_params(), data.shape[0])\n",
    "    found_better_edge = True\n",
    "    \n",
    "    while found_better_edge:\n",
    "        found_better_edge = False\n",
    "        better_edge = (-1,-1)\n",
    "        legal_edges = [(i,j) for i in range(n) for j in range(n) if adj[i,j]==0 and not graphs.path_exists(adj, j, i)]\n",
    "        for edge in legal_edges:\n",
    "            adj[edge] = 1  # add edge to graph\n",
    "            net = GaussNet(adj).fit(data)\n",
    "            score = metric(net.loglikelihood(data), net.num_params(), data.shape[0])\n",
    "            if score > highest_score:  # found a better edge\n",
    "                highest_score = score \n",
    "                found_better_edge = True\n",
    "                better_edge = edge\n",
    "            adj[edge] = 0\n",
    "        if found_better_edge:\n",
    "            adj[better_edge] = 1\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8aaa7cd3-286f-4fea-a401-e98e5f9deb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood: -1069713998.859003 with 79 parameters.\n"
     ]
    }
   ],
   "source": [
    "adj_additive_bic = local_additive_search(data.shape[1], data, BIC)\n",
    "np.save(f'submissions/additive_bic.npy', adj_additive_bic)\n",
    "net = GaussNet(adj_additive_bic).fit(data)\n",
    "print(f'Likelihood: {net.loglikelihood(data)} with {net.num_params()} parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cb55bff-9084-4651-901a-12d5a3875126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood: -1069714003.838056 with 77 parameters.\n"
     ]
    }
   ],
   "source": [
    "adj_additive_aic = local_additive_search(data.shape[1], data, AIC)\n",
    "np.save(f'submissions/additive_aic.npy', adj_additive_aic)\n",
    "net = GaussNet(adj_additive_aic).fit(data)\n",
    "print(f'Likelihood: {net.loglikelihood(data)} with {net.num_params()} parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8e21ac-c8bd-492b-99f0-2bc0cab3e996",
   "metadata": {},
   "source": [
    "### Local Combined Search\n",
    "We start with an empty graph and in each step either add or remove an edge.\n",
    "We choose the action that brings the highest score-increase, until there is none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f85d27e6-6872-47bd-b45b-5bc12d4a9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_combined_search(n: int, data: np.ndarray, metric: Callable) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Performs a local combined search to find an adjacency matrix for a\n",
    "    linear gaussian network that fits the data well.\n",
    "    It uses 'metric' as a score to evaluate gaussian networks.\n",
    "    'metric' should take 3 parameters: \n",
    "        the loglikelihood, the number of parameters and the number of datapoints\n",
    "    \"\"\"\n",
    "    \n",
    "    class EdgeAction(Enum):\n",
    "        ADD = 1\n",
    "        REMOVE = 2\n",
    "    \n",
    "    adj = np.zeros((n,n))  # start with empty adjacency matrix\n",
    "    net = GaussNet(adj).fit(data)\n",
    "    highest_score = metric(net.loglikelihood(data), net.num_params(), data.shape[0])\n",
    "    found_better_action = True\n",
    "    \n",
    "    def do_action(edge_action):\n",
    "        edge = edge_action[0]\n",
    "        action = edge_action[1]\n",
    "        if action == EdgeAction.ADD:\n",
    "            adj[edge] = 1  # add edge to graph\n",
    "        else:\n",
    "            adj[edge] = 0  # remove edge from graph\n",
    "    \n",
    "    def undo_action(edge_action):\n",
    "        edge = edge_action[0]\n",
    "        action = edge_action[1]\n",
    "        if action == EdgeAction.ADD:\n",
    "            adj[edge] = 0  # add edge to graph\n",
    "        else:\n",
    "            adj[edge] = 1  # remove edge from graph\n",
    "    \n",
    "    while found_better_action:\n",
    "        found_better_action = False\n",
    "        better_action = ((-1,-1), EdgeAction.ADD)\n",
    "        edge_adds = [((i,j), EdgeAction.ADD) for i in range(n) for j in range(n) if adj[i,j]==0 and not graphs.path_exists(adj, j, i)]\n",
    "        edge_removes = [((i,j), EdgeAction.REMOVE) for i in range(n) for j in range(n) if adj[i,j]==1]\n",
    "        legal_edge_actions = edge_adds + edge_removes\n",
    "        for (edge, edge_action) in legal_edge_actions:\n",
    "            do_action((edge, edge_action))\n",
    "            net = GaussNet(adj).fit(data)\n",
    "            score = metric(net.loglikelihood(data), net.num_params(), data.shape[0])\n",
    "            if score > highest_score:  # found a better action\n",
    "                highest_score = score \n",
    "                found_better_action = True\n",
    "                better_action = (edge, edge_action)\n",
    "            undo_action((edge, edge_action))\n",
    "        if found_better_action:\n",
    "            do_action(better_action)\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2478339f-4772-4ff4-8627-db88ba06a96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood: -1069713998.859003 with 79 parameters.\n"
     ]
    }
   ],
   "source": [
    "adj_combined_bic = local_combined_search(data.shape[1], data, BIC)\n",
    "np.save(f'submissions/combined_bic.npy', adj_combined_bic)\n",
    "net = GaussNet(adj_combined_bic).fit(data)\n",
    "print(f'Likelihood: {net.loglikelihood(data)} with {net.num_params()} parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "750a03a5-9550-4d2d-83f0-b720b6aa7587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood: -1069714003.838056 with 77 parameters.\n"
     ]
    }
   ],
   "source": [
    "adj_combined_aic = local_combined_search(data.shape[1], data, AIC)\n",
    "np.save(f'submissions/combined_aic.npy', adj_combined_aic)\n",
    "net = GaussNet(adj_combined_aic).fit(data)\n",
    "print(f'Likelihood: {net.loglikelihood(data)} with {net.num_params()} parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446158af-0f74-4560-9cc9-f43218730490",
   "metadata": {},
   "source": [
    "### Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c434a5-c7fe-4377-b401-ed5961241176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing(n: int, data: np.ndarray, metric: Callable, temps: np.ndarray):\n",
    "    \"\"\"\n",
    "    Performs simulated annealing to find an adjacency matrix for a\n",
    "    linear gaussian network that fits the data well.\n",
    "    It uses 'metric' as a score to evaluate gaussian networks.\n",
    "    'metric' should take 3 parameters: \n",
    "        the loglikelihood, the number of parameters and the number of datapoints\n",
    "    'temps' should be a declining series of positive numbers indicating, each indicating\n",
    "    the freedom of the algorithm to choose a locally worse solution in search of a better optimum.\n",
    "    \"\"\"\n",
    "    \n",
    "    class EdgeAction(Enum):\n",
    "        ADD = 1\n",
    "        REMOVE = 2\n",
    "    \n",
    "    adj = np.zeros((n,n))  # start with empty adjacency matrix\n",
    "    net = GaussNet(adj).fit(data)\n",
    "    highest_score = metric(net.loglikelihood(data), net.num_params(), data.shape[0])\n",
    "    found_better_action = True\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

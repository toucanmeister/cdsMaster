{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3028ec-59e2-4591-8fa8-956d138217d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from typing import Dict, Union\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from dataclasses import dataclass\n",
    "import scipy.stats\n",
    "import graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72976cc0-e56c-4cf7-b2ea-c0cb4bd43641",
   "metadata": {},
   "source": [
    "## Having a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae4394f4-1121-4dc4-b69f-5cdf523e78f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('trainset.csv')\n",
    "#_,ax = plt.subplots(nrows=len(dataset.columns), ncols=1, figsize=(10,12))\n",
    "#plt.tight_layout()\n",
    "#for i,column in enumerate(dataset.columns):\n",
    "#    ax[i].hist(dataset[column])\n",
    "#    ax[i].set_xlabel(column)\n",
    "\n",
    "# I'll start by considering quality as a continuous variable with no further changes\n",
    "data = dataset.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211538b-20f5-4508-bad6-192fcba95d15",
   "metadata": {},
   "source": [
    "## Learning a linear gaussian bayes net with a given adjacency matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba775804-7745-4718-b002-1d27a9cf7ede",
   "metadata": {},
   "source": [
    "A linear gaussian bayes net describes a gaussian probability distribution. Each node in such a network itself represents a gaussian distribution over one attribute/variable. Edges between nodes signify dependence of one variable on the other. ($A \\rightarrow B$ means $A$ influences $B$, $B$ is dependent on $A$)\n",
    "\n",
    "For each node $x_i$ , we define its conditional probability distribution:\n",
    "$$\n",
    "p(x_i | \\text{parents}(i)) = \\mathcal{N}\\left( \\beta_{i0} + \\sum_{i \\in \\text{parents}(j)} \\beta_{ij} x_j, \\sigma_i \\right)\n",
    "$$\n",
    "with parameters:\n",
    "- $\\beta_{ij}$: coefficients describing the way $x_j$ influences $x_i$\n",
    "- $\\beta_{i0}$: offset \n",
    "- $\\sigma_i$: conditional variance of $x_i$ (conditioned on $\\text{parents}(i)$)\n",
    "\n",
    "We compute the coefficients and offset by fitting a linear regression, and compute the conditional variance using a formula derived from its definition:\n",
    "$$\n",
    "\\text{Var}[Y|X] = E \\left[(Y - E[Y|X])^2 \\right] \\\\\n",
    "\\text{sampleVar}(y|x) = \\frac{1}{m-1} \\sum_{i=1}^m (y_i - \\hat{y}_x)^2\n",
    "$$\n",
    "where:\n",
    "- $y_i$ is the value of this attribute for each datapoint\n",
    "- $\\hat{y}_x$ is the predicted value of $y_i$ given the values of the other attributes $x$\n",
    "\n",
    "##### Likelihood:\n",
    "Given some data $X = (x^{(1)}, x^{(2)}, ..., x^{(m)})$:\n",
    "$$\n",
    "L(S) = \\prod_{i=1}^m p(x^{(i)} | S, \\theta)\n",
    "$$\n",
    "where $S$ represents the model structure (in our case, the adjacency matrix), and $\\theta$ represents the learned parameters.\n",
    "We only view the likelihood as a function of $S$.\n",
    "We can write down the likelihood for our models in short:\n",
    "$$\n",
    "L(\\text{parents}) = \\prod_{j=1}^m \\prod_{i=1}^n p(x_i^{(j)} | \\text{parents}(x_i)^{(j)}) = \\prod_{j=1}^m \\prod_{i=1}^n  \\mathcal{N}\\left( \\beta_{i0} + \\sum_{i \\in \\text{parents}(k)} \\beta_{ik} x_k^{(j)}, \\sigma_i \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9244e6f0-a90a-4171-b986-dec24c3bf1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class StaticParam:\n",
    "    mu: float\n",
    "    sigma: float\n",
    "\n",
    "@dataclass\n",
    "class DependentParam:\n",
    "    coefficients: np.ndarray\n",
    "    offset: np.ndarray\n",
    "    sigma: float\n",
    "\n",
    "Param = Union[StaticParam, DependentParam] # A param is either static or dependent\n",
    "\n",
    "class GaussNet():\n",
    "    def __init__(self, adj: np.ndarray):\n",
    "        self.adj = adj\n",
    "        self.n = adj.shape[0]  # number of variables\n",
    "        self.params: Dict[int, Param] = {}  # parameters defining gaussian distribution for each variable\n",
    "    \n",
    "    # mode=0 uses explicit linear regressions from sklearn while\n",
    "    # mode=1 uses computations using the covariance matrix with no further packages used\n",
    "    def fit(self, data: np.ndarray, mode=0):\n",
    "        if mode == 0:\n",
    "            return self.__fit1(data)\n",
    "        else:\n",
    "            return self.__fit2(data)\n",
    "    \n",
    "    def __fit1(self, data: np.ndarray):\n",
    "        def compute_static_params():\n",
    "            target_data = data[:, node_idx]\n",
    "            mu = np.mean(target_data)\n",
    "            sigma = np.var(target_data)\n",
    "            return StaticParam(mu, sigma)\n",
    "            \n",
    "        def compute_dependent_params():\n",
    "            target_data = data[:, node_idx]\n",
    "            predictor_data = data[:, graphs.parents(self.adj, node_idx)]\n",
    "            reg = LinearRegression().fit(predictor_data, target_data) # fit a linear regression\n",
    "            coefficients = reg.coef_\n",
    "            offset = reg.intercept_\n",
    "            predicted_data = reg.predict(predictor_data)\n",
    "            sigma = (1/(m-1)) * np.sum((target_data - predicted_data)**2)\n",
    "            return DependentParam(coefficients, offset, sigma)\n",
    "        \n",
    "        m = data.shape[0]\n",
    "        for node_idx in range(self.n):\n",
    "            if graphs.parents(self.adj, node_idx) == []:  # No parents\n",
    "                self.params[node_idx] = compute_static_params()\n",
    "            else:\n",
    "                self.params[node_idx] = compute_dependent_params()\n",
    "        return self\n",
    "    \n",
    "    def __fit2(self, data: np.ndarray):\n",
    "        def compute_static_params() -> StaticParam:\n",
    "            target_data = data[:, node_idx]\n",
    "            mu = np.mean(target_data)\n",
    "            sigma = np.var(target_data)\n",
    "            return StaticParam(mu, sigma)\n",
    "        def compute_dependent_params() -> DependentParam:\n",
    "            target_data = data[:, node_idx]\n",
    "            parents = graphs.parents(self.adj, node_idx)\n",
    "            mu_I = np.mean(target_data)\n",
    "            sigma_full = np.cov(data, rowvar=False)\n",
    "            sigma_IJ = self.__myindex(sigma_full, node_idx, parents)\n",
    "            sigma_JJ = self.__myindex(sigma_full, parents, parents)\n",
    "            mu_J = np.mean(data[:,parents], axis=0)\n",
    "            sigma_II = self.__myindex(sigma_full, node_idx, node_idx)\n",
    "            sigma_JI = self.__myindex(sigma_full, parents, node_idx)\n",
    "            \n",
    "            offset = np.squeeze(mu_I - sigma_IJ @ np.linalg.inv(sigma_JJ) @ np.atleast_2d(mu_J).T)\n",
    "            coefficients = sigma_IJ @ np.linalg.inv(sigma_JJ)\n",
    "            sigma = np.squeeze(sigma_II - coefficients @ sigma_JI)\n",
    "            return DependentParam(coefficients.reshape(len(parents)), offset, sigma)\n",
    "        for node_idx in range(self.n):\n",
    "            if graphs.parents(self.adj, node_idx) == []:  # No parents\n",
    "                self.params[node_idx] = compute_static_params()\n",
    "            else:\n",
    "                self.params[node_idx] = compute_dependent_params()\n",
    "        return self\n",
    "\n",
    "    def predict(self, data: np.ndarray, node_idx: int, toround=False):\n",
    "        predictors = data[:, graphs.parents(self.adj, node_idx)]\n",
    "        param = self.params[node_idx]\n",
    "        if type(param) == StaticParam:\n",
    "            if toround:\n",
    "                return np.repeat(np.around(param.mu), data.shape[0])\n",
    "            else:\n",
    "                return np.repeat(param.mu, data.shape[0])\n",
    "        else:\n",
    "            if toround:\n",
    "                return np.around(param.offset + predictors @ param.coefficients)\n",
    "            else:\n",
    "                return param.offset + predictors @ param.coefficients\n",
    "\n",
    "    def accuracy(self, data: np.ndarray, node_idx: int): # Assumes that node_idx is a categorical variable obtained by rounding the estimate\n",
    "        predicted = np.reshape(self.predict(data, node_idx, toround=True), data.shape[0])\n",
    "        return np.count_nonzero(predicted == data[:,node_idx]) / data.shape[0]\n",
    "\n",
    "    def loglikelihood(self, data: np.ndarray):\n",
    "        acc = 0\n",
    "        for datapoint in data:\n",
    "            for node_idx in range(self.n):\n",
    "                mu = np.squeeze(self.predict(np.atleast_2d(datapoint), node_idx))\n",
    "                acc += scipy.stats.norm.logpdf(datapoint[node_idx], mu, self.params[node_idx].sigma)\n",
    "        return acc\n",
    "    \n",
    "    def __myindex(self, arr, idx_I, idx_J=[]): # Leaves only the indices idx_I and idx_J in array arr\n",
    "        if arr.ndim > 2: return arr\n",
    "        if arr.ndim == 1: return arr[idx_I]\n",
    "        if arr.ndim == 2: return np.atleast_2d(arr[idx_I,:])[:,idx_J]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c0fe34b-5024-4c51-847a-8d608b0cb24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DependentParam(coefficients=array([0.35419866]), offset=1.9564383703769535, sigma=0.5232316131752069)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attributes = data.shape[1]\n",
    "test_adj = np.zeros((num_attributes, num_attributes))\n",
    "test_adj[10,11] = 1 # let's say that residual sugar predicts quality\n",
    "net1 = GaussNet(test_adj)\n",
    "net1.fit(data)\n",
    "net1.params[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f514d16-dedf-4a18-9786-d5cea55b4621",
   "metadata": {},
   "source": [
    "## Second try for gauss nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd20f225-3d8f-4bbc-8a22-c9e3a4e23f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attributes = data.shape[1]\n",
    "test_adj = np.zeros((num_attributes, num_attributes))\n",
    "test_adj[10,11] = 1 # let's say that residual sugar predicts quality\n",
    "net2 = GaussNet(test_adj)\n",
    "net2.fit(data, mode=1) # Using the other mode this time\n",
    "net2.params[11]\n",
    "np.save('submission.npy', test_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74337809-cdcb-49f5-9ad0-911b0d918acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5504587155963303\n",
      "0.5504587155963303\n",
      "-169945633.3528292\n",
      "-169945633.3528292\n"
     ]
    }
   ],
   "source": [
    "print(net1.accuracy(data, 11))\n",
    "print(net2.accuracy(data, 11))\n",
    "print(net1.loglikelihood(data))\n",
    "print(net2.loglikelihood(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b932a-aa97-4e46-b6aa-5687b38a24cc",
   "metadata": {},
   "source": [
    "#### Both modes seem are equivalent!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f549340-703f-44eb-8e81-47a65325561d",
   "metadata": {},
   "source": [
    "### For accuracy, only the last column matters, so let's just try all possibilities\n",
    "\n",
    "That's gonna be $2^{11}=2048$ possibilites.\n",
    "We'll save the maximum accuracy achieved for each number of attributes used in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e21658f-4e07-48e2-83d5-63e7743e03f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy for 0 attributes used: 0.390325271059216, achieved using:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Maximum accuracy for 1 attributes used: 0.5504587155963303, achieved using:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Maximum accuracy for 2 attributes used: 0.5646371976647206, achieved using:\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "Maximum accuracy for 3 attributes used: 0.5746455379482902, achieved using:\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "Maximum accuracy for 4 attributes used: 0.5738115095913261, achieved using:\n",
      "[0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "Maximum accuracy for 5 attributes used: 0.5863219349457881, achieved using:\n",
      "[0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "Maximum accuracy for 6 attributes used: 0.5863219349457881, achieved using:\n",
      "[0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      "Maximum accuracy for 7 attributes used: 0.5888240200166805, achieved using:\n",
      "[0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      "Maximum accuracy for 8 attributes used: 0.5879899916597164, achieved using:\n",
      "[1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0.]\n",
      "Maximum accuracy for 9 attributes used: 0.5921601334445371, achieved using:\n",
      "[1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0.]\n",
      "Maximum accuracy for 10 attributes used: 0.5863219349457881, achieved using:\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.]\n",
      "Maximum accuracy for 11 attributes used: 0.5838198498748958, achieved using:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "columns = np.array(list(itertools.product([0,1], repeat=11)))\n",
    "columns = np.hstack((columns, np.atleast_2d(np.zeros(2**11)).T)) # add a 0, so we dont predict quality by quality\n",
    "\n",
    "max_acc = {}\n",
    "max_acc_idx = {}\n",
    "for i in range(12):\n",
    "    max_acc[i] = -1\n",
    "    max_acc_idx[i] = -1\n",
    "\n",
    "for idx,column in enumerate(columns):\n",
    "    adj = np.zeros((data.shape[1], data.shape[1]))\n",
    "    adj[:,11] = column\n",
    "    acc = GaussNet(adj).fit(data).accuracy(data, 11)\n",
    "    num_attr = np.count_nonzero(column)\n",
    "    if acc > max_acc[num_attr]:\n",
    "        max_acc[num_attr] = acc\n",
    "        max_acc_idx[num_attr] = idx\n",
    "\n",
    "for i in range(12):\n",
    "    column = columns[max_acc_idx[i]]\n",
    "    print(f'Maximum accuracy for {i} attributes used: {max_acc[i]}, achieved using:')\n",
    "    print(column)\n",
    "    adj = np.zeros((data.shape[1], data.shape[1]))\n",
    "    adj[:,11] = column\n",
    "    np.save(f'submissions/sub{i}.npy', adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f986d7-aee6-4d11-9093-b2825c227cd8",
   "metadata": {},
   "source": [
    "# Structure Learning\n",
    "## Score-Based Algorithms\n",
    "For the next algorithms, we will be adding edges to, and removing them from, the graph.\n",
    "When adding edges, we need to make sure we're keeping the DAG structure.\n",
    "An added edge can cause a cycle to appear.\n",
    "In this case, the new edge $A \\rightarrow B$ will be part of the cycle.\n",
    "A cycle will appear if and only if there was a path from $B$ to $A$ in the DAG before the edge was added.\n",
    "We can check for such a path with a search (in this case, DFS) starting from $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6a89d6a-d2d3-4bb1-9611-512f1b7d5ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: False\n",
      "2: True\n",
      "3: True\n",
      "4: False\n",
      "4: True\n",
      "5: False\n",
      "6: False\n",
      "7: True\n",
      "8: False\n",
      "9: False\n"
     ]
    }
   ],
   "source": [
    "# Some test cases for finding paths in a graph\n",
    "test_adj = np.zeros((5,5))\n",
    "print(f'1: {graphs.path_exists(test_adj, 0, 1)}')\n",
    "print(f'2: {graphs.path_exists(test_adj, 0, 0)}')\n",
    "test_adj[0,3] = 1\n",
    "print(f'3: {graphs.path_exists(test_adj, 0, 3)}')\n",
    "print(f'4: {graphs.path_exists(test_adj, 3, 0)}')\n",
    "test_adj[3,4] = 1\n",
    "print(f'4: {graphs.path_exists(test_adj, 0, 4)}')\n",
    "print(f'5: {graphs.path_exists(test_adj, 4, 3)}')\n",
    "print(f'6: {graphs.path_exists(test_adj, 4, 0)}')\n",
    "test_adj[3,2] = 1\n",
    "test_adj[3,1] = 1\n",
    "test_adj[4,4] = 1\n",
    "test_adj[4,1] = 1\n",
    "test_adj[4,2] = 1\n",
    "print(f'7: {graphs.path_exists(test_adj, 0, 4)}')\n",
    "print(f'8: {graphs.path_exists(test_adj, 4, 3)}')\n",
    "print(f'9: {graphs.path_exists(test_adj, 4, 0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e827ad7-cf00-4aca-849c-d0d64140c261",
   "metadata": {},
   "source": [
    "## Scores\n",
    "### Bayesian Information Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15b6a66-5798-4670-aa6a-ae1811846e62",
   "metadata": {},
   "source": [
    "### Akaike Information Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441360a6-b069-45be-b16a-10f5037ed49f",
   "metadata": {},
   "source": [
    "###  Bayesian Dirichlet Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051683fa-41ef-4c62-aa73-cff0f440dcf3",
   "metadata": {},
   "source": [
    "## Search Algorithms\n",
    "### Local Additive Search\n",
    "We start with an empty graph (no edges) and gradually add the legal edge that brings the highest score-increase, until there is none."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28ccee3-0840-4f42-b9e8-690e6524804e",
   "metadata": {},
   "source": [
    "### Local Subtractive Search\n",
    "We start with a full graph (no edges) and gradually add the legal edge that brings the highest score-increase, until there is none."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8e21ac-c8bd-492b-99f0-2bc0cab3e996",
   "metadata": {},
   "source": [
    "### Local Combined Search\n",
    "We start with a randomly initialized graph and in each step either add, remove or flip an edge.\n",
    "We choose the action that brings the highest score-increase, until there is none."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdc11ea-9eb2-4180-9e2c-3331a2d38d20",
   "metadata": {},
   "source": [
    "### Local Search with Larger Neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446158af-0f74-4560-9cc9-f43218730490",
   "metadata": {},
   "source": [
    "### Simulated Annealing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
